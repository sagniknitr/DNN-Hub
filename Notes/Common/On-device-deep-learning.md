## Relevant Methods
- Deep model compression approach 
- Network Optimization
   - Pruning, Weight Sharing, Quantization
- Automatic compressed model generation
   - Knowledge distillation ( teacher , student networks) 
  
### Pruning
- Types
   - Static ( after training)
   - Dynamic (during training)
   - Fine ( only weights)
   - Coarse (weights and layers)

### Student Teacher networks and Model Distillation
- Student learns not only the output but in between representations.